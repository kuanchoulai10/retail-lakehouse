{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaff48be",
   "metadata": {},
   "source": [
    "# Table Maintenance Spark Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb2ab",
   "metadata": {},
   "source": [
    "Reference: [Table Maintenance: The Key To Keeping Your Iceberg Tables Healthy and Performant](https://tabular.io/blog/table-maintenance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5c8206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://1ac96ad2acf7:4040\n",
       "SparkContext available as 'sc' (version = 3.5.5, master = local[*], app id = local-1750487975219)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@74b3152b\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dab5ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS demo.nyc.taxis_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a45d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE demo.nyc.taxis_sample (\n",
    "  `VendorID` BIGINT,\n",
    "  `tpep_pickup_datetime` TIMESTAMP,\n",
    "  `tpep_dropoff_datetime` TIMESTAMP,\n",
    "  `passenger_count` DOUBLE,\n",
    "  `trip_distance` DOUBLE,\n",
    "  `RatecodeID` DOUBLE,\n",
    "  `store_and_fwd_flag` STRING,\n",
    "  `PULocationID` BIGINT,\n",
    "  `DOLocationID` BIGINT,\n",
    "  `payment_type` BIGINT,\n",
    "  `fare_amount` DOUBLE,\n",
    "  `extra` DOUBLE,\n",
    "  `mta_tax` DOUBLE,\n",
    "  `tip_amount` DOUBLE,\n",
    "  `tolls_amount` DOUBLE,\n",
    "  `improvement_surcharge` DOUBLE,\n",
    "  `total_amount` DOUBLE,\n",
    "  `congestion_surcharge` DOUBLE,\n",
    "  `airport_fee` DOUBLE)\n",
    "USING iceberg\n",
    "TBLPROPERTIES(\n",
    "  'write.target-file-size-bytes'='5242880'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997bb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_202201: org.apache.spark.sql.DataFrame = [VendorID: bigint, tpep_pickup_datetime: timestamp_ntz ... 17 more fields]\n",
       "df_202202: org.apache.spark.sql.DataFrame = [VendorID: bigint, tpep_pickup_datetime: timestamp_ntz ... 17 more fields]\n",
       "df_202203: org.apache.spark.sql.DataFrame = [VendorID: bigint, tpep_pickup_datetime: timestamp_ntz ... 17 more fields]\n",
       "df_q1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [VendorID: bigint, tpep_pickup_datetime: timestamp_ntz ... 17 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_202201 = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2022-01.parquet\")\n",
    "val df_202202 = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2022-02.parquet\")\n",
    "val df_202203 = spark.read.parquet(\"/home/iceberg/data/yellow_tripdata_2022-03.parquet\")\n",
    "val df_q1 = df_202201.union(df_202202).union(df_202203)\n",
    "df_q1.write.insertInto(\"nyc.taxis_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cab088",
   "metadata": {},
   "source": [
    "## Rewriting Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad64e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           file_path|file_size_in_bytes|\n",
      "+--------------------+------------------+\n",
      "|s3://warehouse/ny...|           4098378|\n",
      "|s3://warehouse/ny...|           3951238|\n",
      "|s3://warehouse/ny...|           3990037|\n",
      "|s3://warehouse/ny...|           3894699|\n",
      "|s3://warehouse/ny...|           3915456|\n",
      "|s3://warehouse/ny...|           3895987|\n",
      "|s3://warehouse/ny...|           3806277|\n",
      "|s3://warehouse/ny...|           3899172|\n",
      "|s3://warehouse/ny...|           3822840|\n",
      "|s3://warehouse/ny...|           3963021|\n",
      "|s3://warehouse/ny...|           1242601|\n",
      "|s3://warehouse/ny...|           3887960|\n",
      "|s3://warehouse/ny...|           3718812|\n",
      "|s3://warehouse/ny...|           3893136|\n",
      "|s3://warehouse/ny...|           3705416|\n",
      "|s3://warehouse/ny...|           3719417|\n",
      "|s3://warehouse/ny...|           3823555|\n",
      "|s3://warehouse/ny...|           3711923|\n",
      "|s3://warehouse/ny...|           3749498|\n",
      "|s3://warehouse/ny...|           3859935|\n",
      "|s3://warehouse/ny...|           3743970|\n",
      "|s3://warehouse/ny...|           3753909|\n",
      "|s3://warehouse/ny...|           3770138|\n",
      "|s3://warehouse/ny...|           2129775|\n",
      "|s3://warehouse/ny...|           3752993|\n",
      "|s3://warehouse/ny...|           3612792|\n",
      "|s3://warehouse/ny...|           3834524|\n",
      "|s3://warehouse/ny...|           3740475|\n",
      "|s3://warehouse/ny...|           3730257|\n",
      "|s3://warehouse/ny...|           3730578|\n",
      "|s3://warehouse/ny...|           3846061|\n",
      "|s3://warehouse/ny...|           3785702|\n",
      "|s3://warehouse/ny...|           3735734|\n",
      "|s3://warehouse/ny...|           3891194|\n",
      "|s3://warehouse/ny...|           3715606|\n",
      "|s3://warehouse/ny...|           3744550|\n",
      "|s3://warehouse/ny...|           3754543|\n",
      "|s3://warehouse/ny...|           3690781|\n",
      "|s3://warehouse/ny...|           4814844|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT file_path, file_size_in_bytes FROM nyc.taxis_sample.files\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d10355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"ALTER TABLE nyc.taxis_sample UNSET TBLPROPERTIES ('write.target-file-size-bytes')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f26228a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "|rewritten_data_files_count|added_data_files_count|rewritten_bytes_count|failed_data_files_count|\n",
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "|                        39|                     3|            145327784|                      0|\n",
      "+--------------------------+----------------------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CALL demo.system.rewrite_data_files(table => 'nyc.taxis_sample', options => map('target-file-size-bytes','52428800'))\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a9ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           file_path|file_size_in_bytes|\n",
      "+--------------------+------------------+\n",
      "|s3://warehouse/ny...|          49243858|\n",
      "|s3://warehouse/ny...|          48534830|\n",
      "|s3://warehouse/ny...|          40600811|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT file_path, file_size_in_bytes FROM nyc.taxis_sample.files\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523eb893",
   "metadata": {},
   "source": [
    "## Expiring Snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e8c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+---------+\n",
      "|committed_at           |snapshot_id        |operation|\n",
      "+-----------------------+-------------------+---------+\n",
      "|2025-06-21 06:49:14.548|616558229842152742 |append   |\n",
      "|2025-06-21 06:49:40.198|1836423127434635778|replace  |\n",
      "+-----------------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT committed_at, snapshot_id, operation FROM nyc.taxis_sample.snapshots\").show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b264c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|deleted_data_files_count|deleted_position_delete_files_count|deleted_equality_delete_files_count|deleted_manifest_files_count|deleted_manifest_lists_count|deleted_statistics_files_count|\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "|                      39|                                  0|                                  0|                           1|                           1|                             0|\n",
      "+------------------------+-----------------------------------+-----------------------------------+----------------------------+----------------------------+------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "now: java.util.Date = Sat Jun 21 06:49:57 UTC 2025\n",
       "format: java.text.SimpleDateFormat = java.text.SimpleDateFormat@f17b4ca5\n",
       "now_str: String = 2025-06-21 06:49:57.220\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val now = java.util.Calendar.getInstance().getTime()\n",
    "val format = new java.text.SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss.SSS\")\n",
    "val now_str = format.format(now)\n",
    "\n",
    "spark.sql(s\"CALL demo.system.expire_snapshots(table => 'nyc.taxis_sample', older_than => TIMESTAMP '$now_str', retain_last => 1)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131e1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+---------+\n",
      "|committed_at           |snapshot_id        |operation|\n",
      "+-----------------------+-------------------+---------+\n",
      "|2025-06-21 06:49:40.198|1836423127434635778|replace  |\n",
      "+-----------------------+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT committed_at, snapshot_id, operation FROM nyc.taxis_sample.snapshots\").show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181212b6",
   "metadata": {},
   "source": [
    "## Rewriting Manifest Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49290e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+---------------------+\n",
      "|rewritten_manifests_count|added_manifests_count|\n",
      "+-------------------------+---------------------+\n",
      "|                        2|                    1|\n",
      "+-------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CALL demo.system.rewrite_manifests('nyc.taxis_sample')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b91b2-a579-4a91-8f7b-fc0eb210989c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
