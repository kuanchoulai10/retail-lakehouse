{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6633c1",
   "metadata": {},
   "source": [
    "# Write-Audit-Publish with Branches in Apache Iceberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9d173",
   "metadata": {},
   "source": [
    "This notebook runs using the Docker Compose at https://github.com/tabular-io/docker-spark-iceberg. \n",
    "It's based on the [Iceberg - Integrated Audits Demo.ipynb](https://github.com/tabular-io/docker-spark-iceberg/blob/main/spark/notebooks/Iceberg%20-%20Integrated%20Audits%20Demo.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd61c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/21 06:54:30 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1ac96ad2acf7:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff82189900>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bee98",
   "metadata": {},
   "source": [
    "To be able to rerun the notebook several times, let's drop the `permits` table if it exists to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26245f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66e5810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS nyc.permits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead44c0",
   "metadata": {},
   "source": [
    "## Load NYC Film Permits Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f41",
   "metadata": {},
   "source": [
    "For this demo, we will use the [New York City Film Permits dataset](https://data.cityofnewyork.us/City-Government/Film-Permits/tg4x-b46p) available as part of the NYC Open Data initiative. We're using a locally saved copy of a 1000 record sample, but feel free to download the entire dataset to use in this notebook!\n",
    "\n",
    "We'll save the sample dataset into an iceberg table called `permits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cc669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"inferSchema\",\"true\").option(\"multiline\",\"true\").json(\"/home/iceberg/data/nyc_film_permits.json\")\n",
    "df.write.saveAsTable(\"nyc.permits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cf187",
   "metadata": {},
   "source": [
    "Taking a quick peek at the data, you can see that there are a number of permits for different boroughs in New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3170161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Manhattan</td>\n",
       "            <td>518</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|     Manhattan |        518 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31a9ea",
   "metadata": {},
   "source": [
    "## The Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845953b",
   "metadata": {},
   "source": [
    "Tables by default are not configured to allow integrated audits, therefore the first step is enabling this by setting the `write.wap.enabled` table metadata property to `true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf29df0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.permits\n",
    "SET TBLPROPERTIES (\n",
    "    'write.wap.enabled'='true'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405f8a7",
   "metadata": {},
   "source": [
    "We create a branch for the work we want to do. This is a copy-on-write branch, so \"free\" until we start making changes (and \"cheap\" thereafter) since only data that's changed needs to be written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14035a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.permits\n",
    "CREATE BRANCH etl_job_42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437088f6",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b066e",
   "metadata": {},
   "source": [
    "Before writing to the table we set `spark.wap.branch` so that writes (and reads) are against the specified branch of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842e361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.wap.branch', 'etl_job_42')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b749826",
   "metadata": {},
   "source": [
    "Now make the change to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14843243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.permits\n",
    "WHERE borough='Manhattan'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb688c8",
   "metadata": {},
   "source": [
    "## Inspecting the staged/unpublished data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b1256",
   "metadata": {},
   "source": [
    "### Staged/unpublished data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c04cd",
   "metadata": {},
   "source": [
    "The changes are reflected in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbd0d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf332168",
   "metadata": {},
   "source": [
    "Note that because `spark.wap.branch` is set the above query is effectively the same as this one with `VERSION AS OF` for the branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd4b72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits VERSION AS OF 'etl_job_42'\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96fd0",
   "metadata": {},
   "source": [
    "Another syntax (albiet less clear IMHO) for `VERSION AS OF` is a `branch_<branch_name>` suffix to the table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169de151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits.branch_etl_job_42\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85332bf5",
   "metadata": {},
   "source": [
    "### Published data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad40cf1",
   "metadata": {},
   "source": [
    "We can also inspect the unmodified `main` version of the table with `VERSION AS OF`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95df15e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Manhattan</td>\n",
       "            <td>518</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|     Manhattan |        518 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits VERSION AS OF 'main'\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf419df3",
   "metadata": {},
   "source": [
    "The same `branch_` suffix words here too: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270c09c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Manhattan</td>\n",
       "            <td>518</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|     Manhattan |        518 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits.branch_main\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c824f",
   "metadata": {},
   "source": [
    "Any other user of the table will see the full set of data. We can reassure ourselves of this by unsetting `spark.wap.branch` for the session and querying the table without any `VERSION AS OF` modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9f7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.unset('spark.wap.branch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "935d46c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Manhattan</td>\n",
       "            <td>518</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|     Manhattan |        518 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad4c4e",
   "metadata": {},
   "source": [
    "## Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43c910",
   "metadata": {},
   "source": [
    "How you audit the data is up to you. The nice thing about the data being staged is that you can do it within the same ETL job, or have another tool do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90485620",
   "metadata": {},
   "source": [
    "Here's a very simple example of doing in Python. We're going to programatically check that only the four expected boroughs remain in the data. \n",
    "\n",
    "First, we define those that are expected: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d68a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_boroughs = {\"Queens\", \"Brooklyn\", \"Bronx\", \"Staten Island\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dfd72",
   "metadata": {},
   "source": [
    "Then we get a set of the actual boroughs in the staged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce3d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_boroughs = spark.read \\\n",
    "    .option(\"branch\", \"etl_job_42\") \\\n",
    "    .format(\"iceberg\") \\\n",
    "    .load(\"nyc.permits\") \\\n",
    "    .select(\"borough\") \\\n",
    "    .distinct() \\\n",
    "    .toLocalIterator()\n",
    "boroughs = {row[0] for row in distinct_boroughs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30827d",
   "metadata": {},
   "source": [
    "Now we do two checks: \n",
    "\n",
    "1. Compare the length of the expected vs actual set\n",
    "2. Check that the two sets when unioned are still the same length. This is necessary, since the first test isn't sufficient alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb78c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit has passed 🙌🏻\n"
     ]
    }
   ],
   "source": [
    "if (   (len(boroughs)          != len(expected_boroughs)) \\\n",
    "      or (len(boroughs)          != len(set.union(boroughs, expected_boroughs))) \\\n",
    "      or (len(expected_boroughs) != len(set.union(boroughs, expected_boroughs)))):\n",
    "    raise ValueError(f\"Audit failed, borough set does not match expected boroughs: {boroughs} != {expected_boroughs}\")\n",
    "else:\n",
    "    print(f\"Audit has passed 🙌🏻\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a18925",
   "metadata": {},
   "source": [
    "## Publish"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bc16e05",
   "metadata": {},
   "source": [
    "Iceberg supports fast-forward merging of branches back to `main`, using the [`manageSnapshots().fastForwardBranch`](https://iceberg.apache.org/javadoc/latest/org/apache/iceberg/ManageSnapshots.html#fastForwardBranch-java.lang.String-java.lang.String-) API.\n",
    "\n",
    "This isn't yet exposed in Spark, so the existing [`cherrypick`](https://iceberg.apache.org/javadoc/latest/org/apache/iceberg/ManageSnapshots.html#cherrypick-long-) can be used as a slightly less elegant option.\n",
    "\n",
    "ℹ️ Note that `cherrypick` only works for one commit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619fe57",
   "metadata": {},
   "source": [
    "First, we need the snapshot ID of our branch, which we can get from the `.refs` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd5d318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>name</th>\n",
       "            <th>type</th>\n",
       "            <th>snapshot_id</th>\n",
       "            <th>max_reference_age_in_ms</th>\n",
       "            <th>min_snapshots_to_keep</th>\n",
       "            <th>max_snapshot_age_in_ms</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>etl_job_42</td>\n",
       "            <td>BRANCH</td>\n",
       "            <td>8720005413734770031</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>main</td>\n",
       "            <td>BRANCH</td>\n",
       "            <td>8397442454150540251</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "            <td>None</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------+--------+---------------------+-------------------------+-----------------------+------------------------+\n",
       "|       name |   type |         snapshot_id | max_reference_age_in_ms | min_snapshots_to_keep | max_snapshot_age_in_ms |\n",
       "+------------+--------+---------------------+-------------------------+-----------------------+------------------------+\n",
       "| etl_job_42 | BRANCH | 8720005413734770031 |                    None |                  None |                   None |\n",
       "|       main | BRANCH | 8397442454150540251 |                    None |                  None |                   None |\n",
       "+------------+--------+---------------------+-------------------------+-----------------------+------------------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM nyc.permits.refs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c5f09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT snapshot_id\n",
    "FROM nyc.permits.refs\n",
    "WHERE name = 'etl_job_42'\n",
    "\"\"\"\n",
    "\n",
    "wap_snapshot_id = spark.sql(query).head().snapshot_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58520bc1",
   "metadata": {},
   "source": [
    "Now we do the publish, using `cherrypick_snapshot` and the snapshot id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93d6f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>source_snapshot_id</th>\n",
       "            <th>current_snapshot_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>8720005413734770031</td>\n",
       "            <td>8720005413734770031</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+---------------------+\n",
       "|  source_snapshot_id | current_snapshot_id |\n",
       "+---------------------+---------------------+\n",
       "| 8720005413734770031 | 8720005413734770031 |\n",
       "+---------------------+---------------------+"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_query = f\"CALL system.cherrypick_snapshot('nyc.permits', {wap_snapshot_id})\"\n",
    "\n",
    "%sql $publish_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7546923",
   "metadata": {},
   "source": [
    "Finally, we look at the table and revel in the glory that is our published changes 🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d62ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits.branch_etl_job_42\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60be58",
   "metadata": {},
   "source": [
    "We can also inspect the unmodified `main` version of the table with `VERSION AS OF`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97c7a98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits VERSION AS OF 'main'\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0072a24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What if You Don't Want to Publish Changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d1e92",
   "metadata": {},
   "source": [
    "If you don't want to merge the branch you can simply `DROP` it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd455a",
   "metadata": {},
   "source": [
    "### Create a new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dd25215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.permits\n",
    "CREATE BRANCH new_etl_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9bac1e",
   "metadata": {},
   "source": [
    "### Set `spark.wap.branch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b2e2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.wap.branch', 'new_etl_job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f65ce0",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dbd6ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DELETE FROM nyc.permits WHERE borough LIKE '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344e3d0",
   "metadata": {},
   "source": [
    "### Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea44436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------+------------+\n",
       "| borough | permit_cnt |\n",
       "+---------+------------+\n",
       "+---------+------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits \n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5974d6e",
   "metadata": {},
   "source": [
    "#### Whoops 🤭 \n",
    "We deleted all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ebb57d",
   "metadata": {},
   "source": [
    "#### Reassure ourselves that the data is still there in `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87d8ee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>borough</th>\n",
       "            <th>permit_cnt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Queens</td>\n",
       "            <td>96</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Brooklyn</td>\n",
       "            <td>378</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Staten Island</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Bronx</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+------------+\n",
       "|       borough | permit_cnt |\n",
       "+---------------+------------+\n",
       "|        Queens |         96 |\n",
       "|      Brooklyn |        378 |\n",
       "| Staten Island |          1 |\n",
       "|         Bronx |          7 |\n",
       "+---------------+------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT borough, count(*) permit_cnt\n",
    "FROM nyc.permits VERSION AS OF 'main'\n",
    "GROUP BY borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5d357",
   "metadata": {},
   "source": [
    "### Abandon changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0533a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/21 07:09:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$addShutdownHook$2(DiskBlockManager.scala:346)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/06/21 07:09:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/09. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/09\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$addShutdownHook$2(DiskBlockManager.scala:346)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/06/21 07:09:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:359)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2122)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2211)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:550)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/06/21 07:09:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/3f. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/3f\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:359)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2122)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:95)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2305)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2211)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:550)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/06/21 07:09:11 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/1a. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-7969d33e-6c09-4684-9f57-dbbfd3932826/1a\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:174)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:109)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:130)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:117)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:90)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1126)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:364)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:364)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$addShutdownHook$2(DiskBlockManager.scala:346)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "ALTER TABLE nyc.permits\n",
    "DROP BRANCH new_etl_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ed36c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Where Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca251c2",
   "metadata": {},
   "source": [
    "For more information about write-audit-publish see [this talk from Michelle Winters](https://www.youtube.com/watch?v=fXHdeBnpXrg&t=1001s) and [this talk from Sam Redai](https://www.dremio.com/wp-content/uploads/2022/05/Sam-Redai-The-Write-Audit-Publish-Pattern-via-Apache-Iceberg.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
